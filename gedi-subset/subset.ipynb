{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c115eb4c",
   "metadata": {},
   "source": [
    "Code copied from https://repo.ops.maap-project.org/gchang/gedi_tutorials/-/blob/main/2_gedi_l4a_subsets.ipynb\n",
    "\n",
    "From Laura:\n",
    "- Select only variables of user interest (e.g. RH100, RH50 from L2A, cover and pan from L2B, agbd and agbd_se from L4A)\n",
    "- Ability to subset by sensitivity attribute to some level (e.g. where sensitivity >0.95)\n",
    "- Ability to subset using quality flag (L4_quality_flag in L4A, quality_flag in L2A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fcb0bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/geopandas/_compat.py:115: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.8.1-CAPI-1.13.3). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import h5py\n",
    "import numpy as np\n",
    "from profilehooks import timecall\n",
    "from typing import List\n",
    "import multiprocessing\n",
    "\n",
    "from gedi_utils import get_geo_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ed97cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = \"GEDI04_A_2019108045816_O01962_01_T01066_02_002_01_V002.h5\"\n",
    "hf_in = h5py.File(infile, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2d8a18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@timecall\n",
    "def subset_gedi_granule(granule: str, aoi, filter_cols: List = [\"lat_lowestmode\", \"lon_lowestmode\"]):\n",
    "    \"\"\"\n",
    "    Subset a GEDI granule by a polygon in CRS 4326\n",
    "    granule = path to a granule h5 file that's already been downloaded\n",
    "    aoi = a shapely polygon of the aoi\n",
    "    \n",
    "    return path to geojson output\n",
    "    \"\"\"\n",
    "    infile = granule\n",
    "\n",
    "    hf_in = h5py.File(infile, 'r')\n",
    "\n",
    "    result = subset_h5(hf_in, aoi, filter_cols)\n",
    "    \n",
    "    return result\n",
    "\n",
    "#@timecall\n",
    "def spatial_filter(beam, aoi):\n",
    "    \n",
    "    lat = beam['lat_lowestmode'][:]\n",
    "    lon = beam['lon_lowestmode'][:]\n",
    "    i = np.arange(0, len(lat), 1) # index\n",
    "    geo_arr = list(zip(lat,lon, i))\n",
    "    l4adf = pd.DataFrame(geo_arr, columns=[\"lat_lowestmode\", \"lon_lowestmode\", \"i\"])\n",
    "    l4agdf = gpd.GeoDataFrame(l4adf, geometry=gpd.points_from_xy(l4adf.lon_lowestmode, l4adf.lat_lowestmode))\n",
    "    l4agdf.crs = \"EPSG:4326\"\n",
    "    # TODO: is it faster with a spatial index, or rough pass with BBOX first?\n",
    "    bbox = aoi.geometry[0].bounds\n",
    "    l4agdf_clip = l4agdf.cx[bbox[0]:bbox[2], bbox[1]:bbox[3]]\n",
    "    l4agdf_gsrm = l4agdf_clip[l4agdf_clip['geometry'].within(aoi.geometry[0])]\n",
    "    indices = l4agdf_gsrm.i\n",
    "    \n",
    "    return indices\n",
    "\n",
    "#@timecall\n",
    "def subset_h5(hf_in, aoi, filter_cols):\n",
    "    subset_df = pd.DataFrame()\n",
    "    \n",
    "    # loop through BEAMXXXX groups\n",
    "    for v in list(hf_in.keys()):\n",
    "        if v.startswith('BEAM'):\n",
    "            col_names = []\n",
    "            col_val = []\n",
    "            beam = hf_in[v]\n",
    "            \n",
    "            indices = spatial_filter(beam, aoi)\n",
    "            \n",
    "            # TODO: when to spatial subset?\n",
    "            for key, value in beam.items():\n",
    "                # looping through subgroups\n",
    "                if isinstance(value, h5py.Group):\n",
    "                    for key2, value2 in value.items():\n",
    "                        if (key2 not in filter_cols):\n",
    "                            continue\n",
    "                        if (key2 != \"shot_number\"):\n",
    "                             # xvar variables have 2D\n",
    "                            if (key2.startswith('xvar')):\n",
    "                                for r in range(4):\n",
    "                                    col_names.append(key2 + '_' + str(r+1))\n",
    "                                    col_val.append(value2[:, r][indices].tolist())\n",
    "                            else:\n",
    "                                col_names.append(key2)\n",
    "                                col_val.append(value2[:][indices].tolist())\n",
    "                \n",
    "                #looping through base group\n",
    "                else:\n",
    "                    if (key not in filter_cols):\n",
    "                        continue\n",
    "                    # xvar variables have 2D\n",
    "                    if (key.startswith('xvar')):\n",
    "                        for r in range(4):\n",
    "                            col_names.append(key + '_' + str(r+1))\n",
    "                            col_val.append(value[:, r][indices].tolist())\n",
    "                           \n",
    "                    else:\n",
    "                        col_names.append(key)\n",
    "                        col_val.append(value[:][indices].tolist())\n",
    "                    \n",
    "            # create a pandas dataframe        \n",
    "            beam_df = pd.DataFrame(map(list, zip(*col_val)), columns=col_names) \n",
    "            # Inserting BEAM names\n",
    "            beam_df.insert(0, 'BEAM', np.repeat(str(v), len(beam_df.index)).tolist())\n",
    "            # Appending to the subset_df dataframe\n",
    "            subset_df = subset_df.append(beam_df)\n",
    "    \n",
    "    hf_in.close()\n",
    "    # all_gdf = gpd.GeoDataFrame(subset_df, geometry=gpd.points_from_xy(subset_df.lon_lowestmode, subset_df.lat_lowestmode))\n",
    "    all_gdf = gpd.GeoDataFrame(subset_df.loc[:,~subset_df.columns.isin(['lon_lowestmode', 'lat_lowestmode'])],\n",
    "                               geometry=gpd.points_from_xy(subset_df.lon_lowestmode, subset_df.lat_lowestmode))\n",
    "    all_gdf.crs = \"EPSG:4326\"\n",
    "    # TODO: Drop the lon and lat columns after geometry creation(or during)\n",
    "    # TODO: document how many points before and after filtering\n",
    "    #print(f\"All points {all_gdf.shape}\")\n",
    "    subset_gdf = all_gdf[all_gdf['agbd'] >= 0] #Filter out bad? data\n",
    "    # If supplied apply additional filters\n",
    "    # l4_quality_flag == 1\n",
    "    # geolocation/sensitivity_a2 > 0.95\n",
    "    subset_gdf = all_gdf #Doing the spatial search first didn't help at all, so maybe the spatial query is the slow part.\n",
    "    print(f\"Subset points {subset_gdf.shape}\")\n",
    "    \n",
    "    return subset_gdf\n",
    "\n",
    "#@timecall\n",
    "def write_subset_fgb(infile, gdf):\n",
    "    \"\"\"\n",
    "    Write GeoDataFrame to geojson\n",
    "    \"\"\"\n",
    "    outfile = infile.replace('.h5', '.fgb')\n",
    "    gdf.to_file(outfile, driver='FlatGeobuf')\n",
    "    \n",
    "    return outfile\n",
    "\n",
    "@timecall\n",
    "def write_subset_geoparquet(infile, gdf):\n",
    "    \"\"\"\n",
    "    Write GeoDataFrame to geojson\n",
    "    \"\"\"\n",
    "    outfile = infile.replace('.h5', '.geoparquet')\n",
    "    gdf.to_parquet(outfile)\n",
    "    \n",
    "    return outfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1b3433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thinking about a parallel version, but will file access lock?\n",
    "def collect_results(result):\n",
    "    results.extend(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6c66288",
   "metadata": {},
   "outputs": [],
   "source": [
    "gabon_gdf = get_geo_boundary('GAB', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83619eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.6954708, -3.978806, 14.502347, 2.322612)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gabon_gdf.geometry[0].bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57da4d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset points (64209, 6)\n"
     ]
    }
   ],
   "source": [
    "#test = subset_gedi_granule(infile, gabon_gdf)\n",
    "# Filtered version\n",
    "filter_cols = [\"agbd\", \"agbd_se\", \"l4_quality_flag\", \"sensitivity\", \"lat_lowestmode\", \"lon_lowestmode\"]\n",
    "test = subset_gedi_granule(infile, gabon_gdf, filter_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "399120e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64209, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEAM</th>\n",
       "      <th>agbd</th>\n",
       "      <th>agbd_se</th>\n",
       "      <th>l4_quality_flag</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BEAM0000</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.642939</td>\n",
       "      <td>POINT (10.58764 -3.29189)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BEAM0000</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.097681</td>\n",
       "      <td>POINT (10.58794 -3.29146)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BEAM0000</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-252.114624</td>\n",
       "      <td>POINT (10.58824 -3.29104)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BEAM0000</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.101499</td>\n",
       "      <td>POINT (10.58854 -3.29062)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BEAM0000</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.414868</td>\n",
       "      <td>POINT (10.58884 -3.29020)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       BEAM    agbd  agbd_se  l4_quality_flag  sensitivity  \\\n",
       "0  BEAM0000 -9999.0  -9999.0                0    -0.642939   \n",
       "1  BEAM0000 -9999.0  -9999.0                0     8.097681   \n",
       "2  BEAM0000 -9999.0  -9999.0                0  -252.114624   \n",
       "3  BEAM0000 -9999.0  -9999.0                0    -1.101499   \n",
       "4  BEAM0000 -9999.0  -9999.0                0     3.414868   \n",
       "\n",
       "                    geometry  \n",
       "0  POINT (10.58764 -3.29189)  \n",
       "1  POINT (10.58794 -3.29146)  \n",
       "2  POINT (10.58824 -3.29104)  \n",
       "3  POINT (10.58854 -3.29062)  \n",
       "4  POINT (10.58884 -3.29020)  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40439dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce to a set of preselect columns\n",
    "# TODO: it would be better to not even include in the dataframe to start\n",
    "filter_strings = [\"agbd\", \"agbd_se\", \"l4_quality_flag\", \"sensitivity\", \"geometry\"]\n",
    "cols = list(test.columns)\n",
    "def Filter(string, substr):\n",
    "    return [str for str in string if\n",
    "             any(sub in str for sub in substr)]\n",
    "\n",
    "final_table_columns = Filter(cols, filter_strings)\n",
    "#test.drop(columns=test.columns.difference(final_table_columns), inplace=True)\n",
    "test.drop(columns=test.columns.difference(filter_strings), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f6bbee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GEDI04_A_2019108045816_O01962_01_T01066_02_002_01_V002.fgb'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_subset_fgb(infile, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfa339ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:116: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'GEDI04_A_2019108045816_O01962_01_T01066_02_002_01_V002.geoparquet'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to write geoparquet\n",
    "write_subset_geoparquet(infile, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca9ee5b",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cf796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate method using pandas or xarray?\n",
    "pd_h5 = pd.read_hdf(infile, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "276267f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ARCGEN': 'r',\n",
       " 'DXF': 'rw',\n",
       " 'CSV': 'raw',\n",
       " 'OpenFileGDB': 'r',\n",
       " 'ESRIJSON': 'r',\n",
       " 'ESRI Shapefile': 'raw',\n",
       " 'FlatGeobuf': 'rw',\n",
       " 'GeoJSON': 'raw',\n",
       " 'GeoJSONSeq': 'rw',\n",
       " 'GPKG': 'raw',\n",
       " 'GML': 'rw',\n",
       " 'OGR_GMT': 'rw',\n",
       " 'GPX': 'rw',\n",
       " 'GPSTrackMaker': 'rw',\n",
       " 'Idrisi': 'r',\n",
       " 'MapInfo File': 'raw',\n",
       " 'DGN': 'raw',\n",
       " 'OGR_PDS': 'r',\n",
       " 'S57': 'r',\n",
       " 'SQLite': 'raw',\n",
       " 'TopoJSON': 'r'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exploring formats\n",
    "import fiona \n",
    "fiona.supported_drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c55ec446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agbd',\n",
       " 'agbd_pi_lower',\n",
       " 'agbd_pi_upper',\n",
       " 'agbd_a1',\n",
       " 'agbd_a10',\n",
       " 'agbd_a2',\n",
       " 'agbd_a3',\n",
       " 'agbd_a4',\n",
       " 'agbd_a5',\n",
       " 'agbd_a6',\n",
       " 'agbd_pi_lower_a1',\n",
       " 'agbd_pi_lower_a10',\n",
       " 'agbd_pi_lower_a2',\n",
       " 'agbd_pi_lower_a3',\n",
       " 'agbd_pi_lower_a4',\n",
       " 'agbd_pi_lower_a5',\n",
       " 'agbd_pi_lower_a6',\n",
       " 'agbd_pi_upper_a1',\n",
       " 'agbd_pi_upper_a10',\n",
       " 'agbd_pi_upper_a2',\n",
       " 'agbd_pi_upper_a3',\n",
       " 'agbd_pi_upper_a4',\n",
       " 'agbd_pi_upper_a5',\n",
       " 'agbd_pi_upper_a6',\n",
       " 'agbd_se_a1',\n",
       " 'agbd_se_a10',\n",
       " 'agbd_se_a2',\n",
       " 'agbd_se_a3',\n",
       " 'agbd_se_a4',\n",
       " 'agbd_se_a5',\n",
       " 'agbd_se_a6',\n",
       " 'agbd_t_a1',\n",
       " 'agbd_t_a10',\n",
       " 'agbd_t_a2',\n",
       " 'agbd_t_a3',\n",
       " 'agbd_t_a4',\n",
       " 'agbd_t_a5',\n",
       " 'agbd_t_a6',\n",
       " 'agbd_t_pi_lower_a1',\n",
       " 'agbd_t_pi_lower_a10',\n",
       " 'agbd_t_pi_lower_a2',\n",
       " 'agbd_t_pi_lower_a3',\n",
       " 'agbd_t_pi_lower_a4',\n",
       " 'agbd_t_pi_lower_a5',\n",
       " 'agbd_t_pi_lower_a6',\n",
       " 'agbd_t_pi_upper_a1',\n",
       " 'agbd_t_pi_upper_a10',\n",
       " 'agbd_t_pi_upper_a2',\n",
       " 'agbd_t_pi_upper_a3',\n",
       " 'agbd_t_pi_upper_a4',\n",
       " 'agbd_t_pi_upper_a5',\n",
       " 'agbd_t_pi_upper_a6',\n",
       " 'agbd_t_se_a1',\n",
       " 'agbd_t_se_a10',\n",
       " 'agbd_t_se_a2',\n",
       " 'agbd_t_se_a3',\n",
       " 'agbd_t_se_a4',\n",
       " 'agbd_t_se_a5',\n",
       " 'agbd_t_se_a6',\n",
       " 'l4_quality_flag_a1',\n",
       " 'l4_quality_flag_a10',\n",
       " 'l4_quality_flag_a2',\n",
       " 'l4_quality_flag_a3',\n",
       " 'l4_quality_flag_a4',\n",
       " 'l4_quality_flag_a5',\n",
       " 'l4_quality_flag_a6',\n",
       " 'agbd_se',\n",
       " 'agbd_t',\n",
       " 'agbd_t_se',\n",
       " 'sensitivity_a1',\n",
       " 'sensitivity_a10',\n",
       " 'sensitivity_a2',\n",
       " 'sensitivity_a3',\n",
       " 'sensitivity_a4',\n",
       " 'sensitivity_a5',\n",
       " 'sensitivity_a6',\n",
       " 'l4_quality_flag',\n",
       " 'sensitivity']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exploring filtering options\n",
    "filter_strings = [\"agbd\", \"l4_quality_flag\", \"sensitivity\"]\n",
    "cols = list(test.columns)\n",
    "def Filter(string, substr):\n",
    "    return [str for str in string if\n",
    "             any(sub in str for sub in substr)]\n",
    "Filter(cols, filter_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed70b64a",
   "metadata": {},
   "source": [
    "# Bulk Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8ad4bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1009\n",
      "467\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/projects/my-public-bucket/gedi-l4a/gabon'\n",
    "file_list = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('h5')]\n",
    "print(len(file_list))\n",
    "\n",
    "file_list_fgb = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('fgb')]\n",
    "print(len(file_list_fgb))\n",
    "\n",
    "file_list_pq = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('geoparquet')]\n",
    "print(len(file_list_pq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08f71ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset points (64209, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:117: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "\n",
      "  write_subset_geoparquet (/tmp/ipykernel_8553/3431064882.py:111):\n",
      "    0.457 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset points (24866, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:117: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "\n",
      "  write_subset_geoparquet (/tmp/ipykernel_8553/3431064882.py:111):\n",
      "    0.340 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset points (0, 6)\n",
      "Subset points (1846, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:117: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "\n",
      "  write_subset_geoparquet (/tmp/ipykernel_8553/3431064882.py:111):\n",
      "    0.264 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset points (14567, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:117: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "\n",
      "  write_subset_geoparquet (/tmp/ipykernel_8553/3431064882.py:111):\n",
      "    0.333 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset points (39284, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:117: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "\n",
      "  write_subset_geoparquet (/tmp/ipykernel_8553/3431064882.py:111):\n",
      "    0.411 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset points (37779, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:117: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "\n",
      "  write_subset_geoparquet (/tmp/ipykernel_8553/3431064882.py:111):\n",
      "    0.454 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset points (0, 6)\n",
      "Subset points (0, 6)\n",
      "Subset points (66053, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:117: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "\n",
      "  write_subset_geoparquet (/tmp/ipykernel_8553/3431064882.py:111):\n",
      "    0.418 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset points (58430, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:117: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "\n",
      "  write_subset_geoparquet (/tmp/ipykernel_8553/3431064882.py:111):\n",
      "    0.445 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For testing subset the 10 sample granules\n",
    "for file in file_list[:11]:\n",
    "    filter_strings = [\"agbd\", \"agbd_se\", \"l4_quality_flag\", \"sensitivity\", \"lat_lowestmode\", \"lon_lowestmode\"]\n",
    "    subset = subset_gedi_granule(file, gabon_gdf, filter_strings)\n",
    "\n",
    "    if subset.shape[0] > 0 :\n",
    "        write_subset_geoparquet(file, subset)\n",
    "    else:\n",
    "        outfile = 'False'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55ddc52",
   "metadata": {},
   "source": [
    "## Parallel version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1993871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset points (23275, 6)\n",
      "/projects/my-public-bucket/gedi-l4a/gabon/GEDI04_A_2019115021551_O02069_02_T03606_02_002_01_V002.fgb\n",
      "Subset points (58430, 6)\n",
      "Subset points (66053, 6)\n",
      "/projects/my-public-bucket/gedi-l4a/gabon/GEDI04_A_2019115021551_O02069_01_T03606_02_002_01_V002.fgb\n",
      "/projects/my-public-bucket/gedi-l4a/gabon/GEDI04_A_2019114135421_O02061_04_T00905_02_002_01_V002.fgb\n",
      "['/projects/my-public-bucket/gedi-l4a/gabon/GEDI04_A_2019114135421_O02061_04_T00905_02_002_01_V002.fgb', '/projects/my-public-bucket/gedi-l4a/gabon/GEDI04_A_2019115021551_O02069_01_T03606_02_002_01_V002.fgb', '/projects/my-public-bucket/gedi-l4a/gabon/GEDI04_A_2019115021551_O02069_02_T03606_02_002_01_V002.fgb']\n"
     ]
    }
   ],
   "source": [
    "# New variant that does the h5 files in parallel\n",
    "def subset_pre_granule(file):\n",
    "    filter_strings = [\"agbd\", \"agbd_se\", \"l4_quality_flag\", \"sensitivity\", \"lat_lowestmode\", \"lon_lowestmode\"]\n",
    "    subset = subset_gedi_granule(file, gabon_gdf, filter_strings)\n",
    "    if subset.shape[0] > 0 :\n",
    "        outfile = write_subset(file, subset)\n",
    "        print(outfile)\n",
    "    else:\n",
    "        outfile = 'False'\n",
    "        \n",
    "    return outfile\n",
    "\n",
    "pool = multiprocessing.Pool(processes=6)\n",
    "results = pool.map(subset_pre_granule, file_list[9:12])\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "print(results)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca05db1b",
   "metadata": {},
   "source": [
    "# Misc Exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c07dca6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agbd\n",
      "<HDF5 dataset \"agbd\": shape (63659,), type \"<f4\">\n",
      "agbd_se\n",
      "<HDF5 dataset \"agbd_se\": shape (63659,), type \"<f4\">\n",
      "l4_quality_flag\n",
      "<HDF5 dataset \"l4_quality_flag\": shape (63659,), type \"|u1\">\n",
      "lat_lowestmode\n",
      "<HDF5 dataset \"lat_lowestmode\": shape (63659,), type \"<f8\">\n",
      "lon_lowestmode\n",
      "<HDF5 dataset \"lon_lowestmode\": shape (63659,), type \"<f8\">\n",
      "sensitivity\n",
      "<HDF5 dataset \"sensitivity\": shape (63659,), type \"<f4\">\n"
     ]
    }
   ],
   "source": [
    "for k,v in hf_in[\"BEAM0000\"].items():\n",
    "    if (k not in filter_cols):\n",
    "        continue\n",
    "    else:\n",
    "        print(k)\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4eb994a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[:, ~df.columns.isin(['rebounds', 'assists'])]\n",
    "test.loc[:,~test.columns.isin(['lon_lowestmode', 'lat_lowestmode'])].columns\n",
    "\n",
    "test2 = gpd.GeoDataFrame(test.loc[:,~test.columns.isin(['lon_lowestmode', 'lat_lowestmode', 'geometry'])], \n",
    "                         geometry=gpd.points_from_xy(test.lon_lowestmode, test.lat_lowestmode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f23c9d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEAM</th>\n",
       "      <th>agbd</th>\n",
       "      <th>agbd_se</th>\n",
       "      <th>l4_quality_flag</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55637</th>\n",
       "      <td>BEAM0000</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.642939</td>\n",
       "      <td>POINT (10.58764 -3.29189)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55638</th>\n",
       "      <td>BEAM0000</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.097681</td>\n",
       "      <td>POINT (10.58794 -3.29146)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55639</th>\n",
       "      <td>BEAM0000</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-252.114624</td>\n",
       "      <td>POINT (10.58824 -3.29104)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55640</th>\n",
       "      <td>BEAM0000</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.101499</td>\n",
       "      <td>POINT (10.58854 -3.29062)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55641</th>\n",
       "      <td>BEAM0000</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.414868</td>\n",
       "      <td>POINT (10.58884 -3.29020)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           BEAM    agbd  agbd_se  l4_quality_flag  sensitivity  \\\n",
       "55637  BEAM0000 -9999.0  -9999.0                0    -0.642939   \n",
       "55638  BEAM0000 -9999.0  -9999.0                0     8.097681   \n",
       "55639  BEAM0000 -9999.0  -9999.0                0  -252.114624   \n",
       "55640  BEAM0000 -9999.0  -9999.0                0    -1.101499   \n",
       "55641  BEAM0000 -9999.0  -9999.0                0     3.414868   \n",
       "\n",
       "                        geometry  \n",
       "55637  POINT (10.58764 -3.29189)  \n",
       "55638  POINT (10.58794 -3.29146)  \n",
       "55639  POINT (10.58824 -3.29104)  \n",
       "55640  POINT (10.58854 -3.29062)  \n",
       "55641  POINT (10.58884 -3.29020)  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10af19d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
